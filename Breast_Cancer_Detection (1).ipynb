{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EElcvsCt2kmZ"
      },
      "source": [
        "# Breast cancer detection project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbzNnMLL26xY"
      },
      "source": [
        "# I. Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J87yLjL62jky"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtNB8-dH2sfa",
        "outputId": "87986517-f977-4d9b-9bd0-fee4bba6ebe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download already complete (3326820824 bytes).\n",
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/paultimothymooney/breast-histopathology-images/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download histopathology images and save path\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vknJzb2Z2596"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataPath = os.path.join(os.path.expanduser(\"~\"), \".cache/kagglehub/datasets/paultimothymooney/breast-histopathology-images/versions/1\")\n",
        "print(dataPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVLL1vUN3COR"
      },
      "source": [
        "## II. Data Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_aTDzs3DVk",
        "outputId": "b88c4768-6010-4daa-bf1f-5191a299b5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of IDC negative patches:  198738\n",
            "Number of IDC positive patches:  78786\n",
            "Total number of patches:  277524\n"
          ]
        }
      ],
      "source": [
        "# Get all the paths to the images\n",
        "# glob allows for pattern matching to get all the photo paths\n",
        "idc_neg = glob.glob(dataPath +'/*/0/*.png', recursive = True)\n",
        "idc_pos = glob.glob(dataPath +'/*/1/*.png', recursive = True)\n",
        "\n",
        "# Total : 277,524 patches of size 50 x 50 (198,738 IDC negative and 78,786 IDC positive)\n",
        "print(\"Number of IDC negative patches: \", len(idc_neg))\n",
        "print(\"Number of IDC positive patches: \", len(idc_pos))\n",
        "print(\"Total number of patches: \", len(idc_neg) + len(idc_pos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "55V4WM9wK4pO",
        "outputId": "9289650a-abbd-4cce-cc28-c03ce56c605d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def image_to_numpy(image_path, target_size=(50, 50)):\n",
        "    # Load the image in BGR format\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found or unable to load: {image_path}\")\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    img_resized = cv2.resize(img_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return img_resized / 255  # Normalize pixel values to [0,1]\n",
        "\n",
        "# Example usage: Load a sample image\n",
        "example_image_path = dataPath + '/8863/0/8863_idx5_x51_y1251_class0.png'\n",
        "example_tensor = image_to_numpy(example_image_path)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(example_tensor)\n",
        "plt.axis(\"off\")  # Hide axes for better visualization\n",
        "plt.title(\"Sample Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n67lfzQE3GgE",
        "outputId": "96446dfe-a2a2-4c85-de7e-d184d74518e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the tensor:  (50, 50, 3)\n"
          ]
        }
      ],
      "source": [
        "# Function to convert the image to a tensor\n",
        "import cv2\n",
        "\n",
        "def image_to_numpy(image_path, target_size=(50, 50)):\n",
        "    # Load the image in BGR format\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found or unable to load: {image_path}\")\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    img_resized = cv2.resize(img_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return img_resized / 255\n",
        "\n",
        "# Example usage\n",
        "example_image_path = '/8863/0/8863_idx5_x51_y1251_class0.png'\n",
        "example_tensor = image_to_numpy(dataPath + example_image_path)\n",
        "print(\"Shape of the tensor: \", example_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "tg-JS1sM3H7C",
        "outputId": "728a445e-9559-4cab-eff7-4e8e5e6fb97c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to plot the image\n",
        "def plot_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "\n",
        "# Example usage\n",
        "plot_image(idc_neg[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojsmdcnB7vRP"
      },
      "source": [
        "## III. Data analysis & Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s-D9ar7GQ34",
        "outputId": "cde4dc42-99df-48c4-c366-b1f861709487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24000, 50, 50, 3)\n",
            "(24000,)\n",
            "\n",
            "(19200, 50, 50, 3)\n",
            "(19200,)\n",
            "(4800, 50, 50, 3)\n",
            "(4800,)\n"
          ]
        }
      ],
      "source": [
        "# Get 12000 random idc negative image and convert to numpy arrays\n",
        "idc_neg_numpy = []\n",
        "\n",
        "for i in random.sample(range(0, len(idc_neg)), 12000):\n",
        "    idc_neg_numpy.append(image_to_numpy(idc_neg[i]))\n",
        "\n",
        "# Get 12000 random idc positive image and convert to numpy arrays\n",
        "idc_pos_numpy = []\n",
        "\n",
        "for i in random.sample(range(0, len(idc_pos)), 12000):\n",
        "    idc_pos_numpy.append(image_to_numpy(idc_pos[i]))\n",
        "\n",
        "# We combine the negative and positive data and create a y lable numpy array.\n",
        "X = np.array(idc_neg_numpy + idc_pos_numpy)\n",
        "y = np.array([0] * len(idc_neg_numpy) + [1] * len(idc_pos_numpy))\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print()\n",
        "\n",
        "# get X train, X test, y train, y test with sklearn.model_selection's train_test_split\n",
        "# test split is 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk5PoyUu3UtB"
      },
      "source": [
        "## IV. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5z0QXfhMkoG"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9G1f76r3UKM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kruo991U3XR2",
        "outputId": "0800296c-f671-43d1-b83d-c493b89a5b55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#Initialize the Sequential model:\n",
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Conv2D(32, (5, 5), strides=(1, 1), input_shape=(50, 50, 3), activation='relu', data_format=\"channels_last\"))\n",
        "model1.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Compiling the model, loss: categorical crossentropy, it is the most popular for these kind of problems,\n",
        "#metrics: accuracy (We want to know the accuracy after each epoch.)\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T9ukOfIDhkt",
        "outputId": "a6a40b4c-eb1e-4850-d8aa-3d01c45bf418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m118/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5141 - loss: 0.7629\n",
            "Epoch 1: val_loss improved from inf to 0.66882, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5142 - loss: 0.7614 - val_accuracy: 0.4924 - val_loss: 0.6688\n",
            "Epoch 2/10\n",
            "\u001b[1m118/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6037 - loss: 0.6454\n",
            "Epoch 2: val_loss improved from 0.66882 to 0.62480, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6051 - loss: 0.6451 - val_accuracy: 0.7443 - val_loss: 0.6248\n",
            "Epoch 3/10\n",
            "\u001b[1m118/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7252 - loss: 0.5893\n",
            "Epoch 3: val_loss improved from 0.62480 to 0.54026, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7254 - loss: 0.5886 - val_accuracy: 0.7398 - val_loss: 0.5403\n",
            "Epoch 4/10\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7656 - loss: 0.5044\n",
            "Epoch 4: val_loss improved from 0.54026 to 0.52401, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7656 - loss: 0.5043 - val_accuracy: 0.7646 - val_loss: 0.5240\n",
            "Epoch 5/10\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7645 - loss: 0.5077\n",
            "Epoch 5: val_loss improved from 0.52401 to 0.45793, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7646 - loss: 0.5075 - val_accuracy: 0.8005 - val_loss: 0.4579\n",
            "Epoch 6/10\n",
            "\u001b[1m118/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7815 - loss: 0.4764\n",
            "Epoch 6: val_loss did not improve from 0.45793\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7816 - loss: 0.4761 - val_accuracy: 0.7948 - val_loss: 0.4676\n",
            "Epoch 7/10\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7810 - loss: 0.4712\n",
            "Epoch 7: val_loss improved from 0.45793 to 0.44660, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7811 - loss: 0.4711 - val_accuracy: 0.8005 - val_loss: 0.4466\n",
            "Epoch 8/10\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8020 - loss: 0.4452\n",
            "Epoch 8: val_loss improved from 0.44660 to 0.43700, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8020 - loss: 0.4453 - val_accuracy: 0.8070 - val_loss: 0.4370\n",
            "Epoch 9/10\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8037 - loss: 0.4386\n",
            "Epoch 9: val_loss improved from 0.43700 to 0.43233, saving model to weights1.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8037 - loss: 0.4387 - val_accuracy: 0.8073 - val_loss: 0.4323\n",
            "Epoch 10/10\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8035 - loss: 0.4389\n",
            "Epoch 10: val_loss did not improve from 0.43233\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8034 - loss: 0.4390 - val_accuracy: 0.7914 - val_loss: 0.4634\n"
          ]
        }
      ],
      "source": [
        "# Stop training the model if validation does not improve as to not overfit the model\n",
        "early_stopping=EarlyStopping(patience=10, verbose=1)\n",
        "\n",
        "# Saves the weights of the best models\n",
        "checkpointer=ModelCheckpoint(filepath='weights1.keras', save_best_only=True, verbose=1)\n",
        "\n",
        "#Fit with 10 epochs of 128 batch_size and 0.2 validation split\n",
        "#Specify which callbacks or 'plugins' to use.\n",
        "network_history = model1.fit(X_train, y_train, batch_size=128,\n",
        "                            epochs=10, verbose=1, validation_split=0.2,\n",
        "                  callbacks=[checkpointer, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV5D-MGmF7Qr",
        "outputId": "ce422193-cfa1-49b3-9ad1-5901c6568e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4410\n",
            "Loss on test set: 0.4359928369522095 Accuracy on test set: 0.8050000071525574\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model(\"weights1.keras\")\n",
        "test_err = model1.evaluate(X_test,y_test)\n",
        "print(\"Loss on test set:\", test_err[0], \"Accuracy on test set:\", test_err[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgbjghI9F91_",
        "outputId": "7f07bfc2-8aea-462e-e2bb-544932fe1913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "[0.7779806]\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "[1]\n",
            "0\n",
            "Test accuracy: 0.805\n",
            "Precision 0.8055103178719266\n",
            "Recall 0.8050753838725857\n",
            "f1_score 0.8049430745326891\n",
            "\n",
            " Confusion matrix \n",
            "[[1973  418]\n",
            " [ 518 1891]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, confusion_matrix\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "print(y_pred[0])\n",
        "y_pred = model1.predict(X_test) > 0.5\n",
        "y_pred = y_pred.astype(int)\n",
        "print(y_pred[0])\n",
        "y_true = y_test\n",
        "print(y_true[0])\n",
        "\n",
        "print(\"Test accuracy: %g\" %(accuracy_score(y_true, y_pred)))\n",
        "print(\"Precision\", precision_score(y_true, y_pred, average=\"macro\")) #one vs rest averages or global\n",
        "print(\"Recall\", recall_score(y_true, y_pred, average=\"macro\")) #macro calculates the average of the recall for each class\n",
        "print(\"f1_score\", f1_score(y_true, y_pred, average=\"macro\")) #macro is good for balanced data set, micro is good for imbalanced\n",
        "print(\"\\n Confusion matrix \")\n",
        "conf=confusion_matrix(y_true, y_pred)\n",
        "print(conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Le1iCgL4It"
      },
      "source": [
        "### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DksyXInPOqIl",
        "outputId": "f23a32ab-927a-42a7-8b55-808daa541f7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.5928 - Recall: 0.5293 - accuracy: 0.5824 - loss: 1.4599\n",
            "Epoch 1: val_loss improved from inf to 0.74754, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - Precision: 0.5946 - Recall: 0.5307 - accuracy: 0.5840 - loss: 1.4536 - val_Precision: 0.6037 - val_Recall: 0.9651 - val_accuracy: 0.6607 - val_loss: 0.7475\n",
            "Epoch 2/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8002 - Recall: 0.7645 - accuracy: 0.7868 - loss: 0.5607\n",
            "Epoch 2: val_loss improved from 0.74754 to 0.47091, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8003 - Recall: 0.7644 - accuracy: 0.7868 - loss: 0.5602 - val_Precision: 0.7792 - val_Recall: 0.8584 - val_accuracy: 0.8047 - val_loss: 0.4709\n",
            "Epoch 3/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8035 - Recall: 0.7658 - accuracy: 0.7910 - loss: 0.4937\n",
            "Epoch 3: val_loss did not improve from 0.47091\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8035 - Recall: 0.7659 - accuracy: 0.7910 - loss: 0.4936 - val_Precision: 0.7565 - val_Recall: 0.8897 - val_accuracy: 0.7987 - val_loss: 0.4742\n",
            "Epoch 4/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Precision: 0.7955 - Recall: 0.7870 - accuracy: 0.7938 - loss: 0.4702\n",
            "Epoch 4: val_loss did not improve from 0.47091\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - Precision: 0.7955 - Recall: 0.7871 - accuracy: 0.7939 - loss: 0.4702 - val_Precision: 0.7034 - val_Recall: 0.9246 - val_accuracy: 0.7638 - val_loss: 0.4942\n",
            "Epoch 5/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8002 - Recall: 0.8113 - accuracy: 0.8028 - loss: 0.4542\n",
            "Epoch 5: val_loss improved from 0.47091 to 0.43277, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8001 - Recall: 0.8111 - accuracy: 0.8028 - loss: 0.4543 - val_Precision: 0.7658 - val_Recall: 0.8825 - val_accuracy: 0.8034 - val_loss: 0.4328\n",
            "Epoch 6/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8134 - Recall: 0.8132 - accuracy: 0.8129 - loss: 0.4349\n",
            "Epoch 6: val_loss improved from 0.43277 to 0.41175, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8133 - Recall: 0.8131 - accuracy: 0.8128 - loss: 0.4350 - val_Precision: 0.7833 - val_Recall: 0.8717 - val_accuracy: 0.8125 - val_loss: 0.4117\n",
            "Epoch 7/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Precision: 0.8121 - Recall: 0.8137 - accuracy: 0.8117 - loss: 0.4384\n",
            "Epoch 7: val_loss did not improve from 0.41175\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - Precision: 0.8120 - Recall: 0.8136 - accuracy: 0.8117 - loss: 0.4385 - val_Precision: 0.7773 - val_Recall: 0.8774 - val_accuracy: 0.8102 - val_loss: 0.4121\n",
            "Epoch 8/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8107 - Recall: 0.8198 - accuracy: 0.8169 - loss: 0.4241\n",
            "Epoch 8: val_loss did not improve from 0.41175\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8106 - Recall: 0.8198 - accuracy: 0.8168 - loss: 0.4243 - val_Precision: 0.8127 - val_Recall: 0.8348 - val_accuracy: 0.8185 - val_loss: 0.4288\n",
            "Epoch 9/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8206 - Recall: 0.7999 - accuracy: 0.8128 - loss: 0.4333\n",
            "Epoch 9: val_loss improved from 0.41175 to 0.41115, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - Precision: 0.8204 - Recall: 0.8000 - accuracy: 0.8127 - loss: 0.4334 - val_Precision: 0.8288 - val_Recall: 0.8271 - val_accuracy: 0.8255 - val_loss: 0.4112\n",
            "Epoch 10/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8198 - Recall: 0.8018 - accuracy: 0.8125 - loss: 0.4375\n",
            "Epoch 10: val_loss did not improve from 0.41115\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8198 - Recall: 0.8020 - accuracy: 0.8126 - loss: 0.4373 - val_Precision: 0.7249 - val_Recall: 0.9071 - val_accuracy: 0.7781 - val_loss: 0.4631\n",
            "Epoch 11/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.7997 - Recall: 0.8025 - accuracy: 0.8034 - loss: 0.4444\n",
            "Epoch 11: val_loss did not improve from 0.41115\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.7999 - Recall: 0.8025 - accuracy: 0.8035 - loss: 0.4443 - val_Precision: 0.7301 - val_Recall: 0.9395 - val_accuracy: 0.7930 - val_loss: 0.4561\n",
            "Epoch 12/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8172 - Recall: 0.8128 - accuracy: 0.8165 - loss: 0.4176\n",
            "Epoch 12: val_loss improved from 0.41115 to 0.40743, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8173 - Recall: 0.8128 - accuracy: 0.8165 - loss: 0.4176 - val_Precision: 0.7794 - val_Recall: 0.8866 - val_accuracy: 0.8151 - val_loss: 0.4074\n",
            "Epoch 13/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8157 - Recall: 0.8384 - accuracy: 0.8240 - loss: 0.4074\n",
            "Epoch 13: val_loss improved from 0.40743 to 0.39914, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - Precision: 0.8158 - Recall: 0.8383 - accuracy: 0.8240 - loss: 0.4074 - val_Precision: 0.8525 - val_Recall: 0.7860 - val_accuracy: 0.8224 - val_loss: 0.3991\n",
            "Epoch 14/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8189 - Recall: 0.8211 - accuracy: 0.8168 - loss: 0.4171\n",
            "Epoch 14: val_loss did not improve from 0.39914\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.8188 - Recall: 0.8212 - accuracy: 0.8168 - loss: 0.4171 - val_Precision: 0.7714 - val_Recall: 0.9071 - val_accuracy: 0.8164 - val_loss: 0.4214\n",
            "Epoch 15/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8245 - Recall: 0.8276 - accuracy: 0.8262 - loss: 0.4079\n",
            "Epoch 15: val_loss did not improve from 0.39914\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - Precision: 0.8244 - Recall: 0.8277 - accuracy: 0.8262 - loss: 0.4078 - val_Precision: 0.8263 - val_Recall: 0.8322 - val_accuracy: 0.8260 - val_loss: 0.4001\n",
            "Epoch 16/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8209 - Recall: 0.8219 - accuracy: 0.8230 - loss: 0.4134\n",
            "Epoch 16: val_loss improved from 0.39914 to 0.39332, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - Precision: 0.8210 - Recall: 0.8220 - accuracy: 0.8231 - loss: 0.4133 - val_Precision: 0.7916 - val_Recall: 0.8887 - val_accuracy: 0.8247 - val_loss: 0.3933\n",
            "Epoch 17/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8211 - Recall: 0.8343 - accuracy: 0.8281 - loss: 0.4018\n",
            "Epoch 17: val_loss improved from 0.39332 to 0.38609, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8212 - Recall: 0.8344 - accuracy: 0.8281 - loss: 0.4016 - val_Precision: 0.7856 - val_Recall: 0.9153 - val_accuracy: 0.8302 - val_loss: 0.3861\n",
            "Epoch 18/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8278 - Recall: 0.8378 - accuracy: 0.8313 - loss: 0.3993\n",
            "Epoch 18: val_loss improved from 0.38609 to 0.38327, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - Precision: 0.8278 - Recall: 0.8378 - accuracy: 0.8313 - loss: 0.3992 - val_Precision: 0.8008 - val_Recall: 0.9035 - val_accuracy: 0.8370 - val_loss: 0.3833\n",
            "Epoch 19/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8309 - Recall: 0.8439 - accuracy: 0.8376 - loss: 0.3837\n",
            "Epoch 19: val_loss did not improve from 0.38327\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8308 - Recall: 0.8438 - accuracy: 0.8375 - loss: 0.3838 - val_Precision: 0.7069 - val_Recall: 0.9477 - val_accuracy: 0.7740 - val_loss: 0.4638\n",
            "Epoch 20/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8314 - Recall: 0.8361 - accuracy: 0.8334 - loss: 0.3956\n",
            "Epoch 20: val_loss did not improve from 0.38327\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.8315 - Recall: 0.8361 - accuracy: 0.8334 - loss: 0.3955 - val_Precision: 0.7943 - val_Recall: 0.8974 - val_accuracy: 0.8299 - val_loss: 0.4021\n",
            "Epoch 21/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8436 - Recall: 0.8489 - accuracy: 0.8433 - loss: 0.3781\n",
            "Epoch 21: val_loss improved from 0.38327 to 0.37901, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - Precision: 0.8435 - Recall: 0.8487 - accuracy: 0.8432 - loss: 0.3781 - val_Precision: 0.8086 - val_Recall: 0.8907 - val_accuracy: 0.8375 - val_loss: 0.3790\n",
            "Epoch 22/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8430 - Recall: 0.8474 - accuracy: 0.8452 - loss: 0.3679\n",
            "Epoch 22: val_loss did not improve from 0.37901\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - Precision: 0.8429 - Recall: 0.8473 - accuracy: 0.8451 - loss: 0.3681 - val_Precision: 0.7739 - val_Recall: 0.9236 - val_accuracy: 0.8242 - val_loss: 0.4028\n",
            "Epoch 23/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8430 - Recall: 0.8550 - accuracy: 0.8488 - loss: 0.3714\n",
            "Epoch 23: val_loss did not improve from 0.37901\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8429 - Recall: 0.8549 - accuracy: 0.8487 - loss: 0.3716 - val_Precision: 0.8202 - val_Recall: 0.8917 - val_accuracy: 0.8458 - val_loss: 0.3843\n",
            "Epoch 24/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8464 - Recall: 0.8392 - accuracy: 0.8451 - loss: 0.3731\n",
            "Epoch 24: val_loss did not improve from 0.37901\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8463 - Recall: 0.8392 - accuracy: 0.8451 - loss: 0.3731 - val_Precision: 0.7913 - val_Recall: 0.9046 - val_accuracy: 0.8305 - val_loss: 0.3882\n",
            "Epoch 25/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Precision: 0.8443 - Recall: 0.8531 - accuracy: 0.8489 - loss: 0.3681\n",
            "Epoch 25: val_loss did not improve from 0.37901\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - Precision: 0.8444 - Recall: 0.8530 - accuracy: 0.8489 - loss: 0.3681 - val_Precision: 0.7649 - val_Recall: 0.9312 - val_accuracy: 0.8198 - val_loss: 0.4066\n",
            "Epoch 26/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8382 - Recall: 0.8566 - accuracy: 0.8462 - loss: 0.3696\n",
            "Epoch 26: val_loss improved from 0.37901 to 0.36055, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8382 - Recall: 0.8566 - accuracy: 0.8462 - loss: 0.3696 - val_Precision: 0.8366 - val_Recall: 0.8748 - val_accuracy: 0.8497 - val_loss: 0.3606\n",
            "Epoch 27/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8560 - Recall: 0.8495 - accuracy: 0.8524 - loss: 0.3673\n",
            "Epoch 27: val_loss improved from 0.36055 to 0.35932, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8559 - Recall: 0.8494 - accuracy: 0.8523 - loss: 0.3673 - val_Precision: 0.8454 - val_Recall: 0.8558 - val_accuracy: 0.8474 - val_loss: 0.3593\n",
            "Epoch 28/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8614 - Recall: 0.8507 - accuracy: 0.8564 - loss: 0.3566\n",
            "Epoch 28: val_loss did not improve from 0.35932\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - Precision: 0.8613 - Recall: 0.8507 - accuracy: 0.8563 - loss: 0.3566 - val_Precision: 0.7837 - val_Recall: 0.9051 - val_accuracy: 0.8250 - val_loss: 0.3969\n",
            "Epoch 29/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8492 - Recall: 0.8594 - accuracy: 0.8539 - loss: 0.3534\n",
            "Epoch 29: val_loss improved from 0.35932 to 0.35879, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - Precision: 0.8492 - Recall: 0.8593 - accuracy: 0.8539 - loss: 0.3535 - val_Precision: 0.8370 - val_Recall: 0.8692 - val_accuracy: 0.8477 - val_loss: 0.3588\n",
            "Epoch 30/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8463 - Recall: 0.8602 - accuracy: 0.8533 - loss: 0.3578\n",
            "Epoch 30: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.8463 - Recall: 0.8601 - accuracy: 0.8532 - loss: 0.3579 - val_Precision: 0.8568 - val_Recall: 0.8409 - val_accuracy: 0.8479 - val_loss: 0.3609\n",
            "Epoch 31/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8463 - Recall: 0.8390 - accuracy: 0.8458 - loss: 0.3652\n",
            "Epoch 31: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - Precision: 0.8464 - Recall: 0.8393 - accuracy: 0.8459 - loss: 0.3650 - val_Precision: 0.8754 - val_Recall: 0.7927 - val_accuracy: 0.8375 - val_loss: 0.3762\n",
            "Epoch 32/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8493 - Recall: 0.8575 - accuracy: 0.8529 - loss: 0.3535\n",
            "Epoch 32: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8492 - Recall: 0.8575 - accuracy: 0.8529 - loss: 0.3535 - val_Precision: 0.7607 - val_Recall: 0.9364 - val_accuracy: 0.8182 - val_loss: 0.4136\n",
            "Epoch 33/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8509 - Recall: 0.8693 - accuracy: 0.8612 - loss: 0.3441\n",
            "Epoch 33: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8508 - Recall: 0.8692 - accuracy: 0.8611 - loss: 0.3442 - val_Precision: 0.8612 - val_Recall: 0.8086 - val_accuracy: 0.8367 - val_loss: 0.3800\n",
            "Epoch 34/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8525 - Recall: 0.8530 - accuracy: 0.8550 - loss: 0.3521\n",
            "Epoch 34: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8525 - Recall: 0.8531 - accuracy: 0.8551 - loss: 0.3521 - val_Precision: 0.8293 - val_Recall: 0.8774 - val_accuracy: 0.8461 - val_loss: 0.3665\n",
            "Epoch 35/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8537 - Recall: 0.8673 - accuracy: 0.8601 - loss: 0.3425\n",
            "Epoch 35: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8537 - Recall: 0.8673 - accuracy: 0.8601 - loss: 0.3426 - val_Precision: 0.8737 - val_Recall: 0.7630 - val_accuracy: 0.8237 - val_loss: 0.3830\n",
            "Epoch 36/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8624 - Recall: 0.8404 - accuracy: 0.8542 - loss: 0.3476\n",
            "Epoch 36: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.8623 - Recall: 0.8407 - accuracy: 0.8543 - loss: 0.3475 - val_Precision: 0.7921 - val_Recall: 0.9112 - val_accuracy: 0.8336 - val_loss: 0.3963\n",
            "Epoch 37/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8598 - Recall: 0.8598 - accuracy: 0.8613 - loss: 0.3455\n",
            "Epoch 37: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - Precision: 0.8598 - Recall: 0.8598 - accuracy: 0.8613 - loss: 0.3456 - val_Precision: 0.8266 - val_Recall: 0.8779 - val_accuracy: 0.8445 - val_loss: 0.3714\n",
            "Epoch 38/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8631 - Recall: 0.8749 - accuracy: 0.8676 - loss: 0.3333\n",
            "Epoch 38: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - Precision: 0.8630 - Recall: 0.8747 - accuracy: 0.8675 - loss: 0.3335 - val_Precision: 0.8159 - val_Recall: 0.8825 - val_accuracy: 0.8393 - val_loss: 0.3738\n",
            "Epoch 39/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Precision: 0.8510 - Recall: 0.8833 - accuracy: 0.8660 - loss: 0.3288\n",
            "Epoch 39: val_loss did not improve from 0.35879\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - Precision: 0.8510 - Recall: 0.8831 - accuracy: 0.8659 - loss: 0.3289 - val_Precision: 0.7883 - val_Recall: 0.9210 - val_accuracy: 0.8344 - val_loss: 0.3775\n",
            "Epoch 40/40\n",
            "\u001b[1m119/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Precision: 0.8559 - Recall: 0.8579 - accuracy: 0.8584 - loss: 0.3323\n",
            "Epoch 40: val_loss improved from 0.35879 to 0.35830, saving model to weights2.keras\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - Precision: 0.8560 - Recall: 0.8580 - accuracy: 0.8585 - loss: 0.3323 - val_Precision: 0.8212 - val_Recall: 0.8953 - val_accuracy: 0.8479 - val_loss: 0.3583\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.8089 - Recall: 0.8880 - accuracy: 0.8405 - loss: 0.3785\n",
            "Loss on test set: 0.36748233437538147 Accuracy on test set: 0.8479166626930237\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Test accuracy: 0.847917\n",
            "Precision: 0.8505620189804464\n",
            "Recall: 0.8477535882015008\n",
            "f1_score: 0.8475847401006638\n",
            "\n",
            "Confusion matrix:\n",
            "[[1923  468]\n",
            " [ 262 2147]]\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "# First Conv Block\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Second Conv Block\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Third Conv Block\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Fourth --> no max Pooling as to not lose too much info\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Fifth\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "#Sixth -- no max pooling\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Seventh\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "#Eighth\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "# Global Average Pooling + Fully Connected\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "model2.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(patience=15, verbose=1)\n",
        "checkpointer = ModelCheckpoint(filepath='weights2.keras', save_best_only=True, verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "network_history = model2.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=128, epochs=40, verbose=1, validation_split=0.2,\n",
        "    callbacks=[checkpointer, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best model and evaluate\n",
        "from keras.models import load_model\n",
        "model2 = load_model(\"weights2.keras\")\n",
        "test_err = model2.evaluate(X_test, y_test)\n",
        "print(\"Loss on test set:\", test_err[0], \"Accuracy on test set:\", test_err[1])\n",
        "\n",
        "# Metrics Evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "y_pred = model2.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "y_true = y_test\n",
        "\n",
        "print(\"Test accuracy: %g\" % (accuracy_score(y_true, y_pred)))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"f1_score:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "print(\"\\nConfusion matrix:\")\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "print(conf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3), padding='same'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # Downsampling\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Block 3\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Block 4\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Global Average Pooling instead of Flatten\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))  # High dropout near dense layers\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(patience=15, verbose=1)\n",
        "checkpointer = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "network_history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=128, epochs=40, verbose=1, validation_split=0.2,\n",
        "    callbacks=[checkpointer, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best model and evaluate\n",
        "from keras.models import load_model\n",
        "model = load_model(\"best_model.keras\")\n",
        "test_err = model.evaluate(X_test, y_test)\n",
        "print(\"Loss on test set:\", test_err[0], \"Accuracy on test set:\", test_err[1])\n",
        "\n",
        "# Metrics Evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "y_true = y_test\n",
        "\n",
        "print(\"Test accuracy: %g\" % (accuracy_score(y_true, y_pred)))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"f1_score:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "print(\"\\nConfusion matrix:\")\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "print(conf)\n"
      ],
      "metadata": {
        "id": "r4wXDkOXq2fw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}